{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# \"Don't Patronize Me\" Machine Learning Model Experimentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1635215172108
        }
      },
      "outputs": [],
      "source": [
        "# azureml-core of version 1.0.72 or higher is required\n",
        "# azureml-dataprep[pandas] of version 1.1.34 or higher is required\n",
        "from azureml.core import Workspace, Dataset, Environment\n",
        "from azureml.core.conda_dependencies import CondaDependencies\n",
        "\n",
        "subscription_id = None # obscured for security\n",
        "resource_group = 'CS4650'\n",
        "workspace_name = '4650_Project'\n",
        "\n",
        "workspace = Workspace(subscription_id, resource_group, workspace_name)\n",
        "env = Environment.get(workspace=workspace, name=\"Project_4650\")\n",
        "\n",
        "dataset = Dataset.get_by_name(workspace, name=\"Don\\'t Patronize Me\")\n",
        "df = dataset.to_pandas_dataframe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Preprocessing\n",
        "Trim the dataframe of the NaN rows, change the names of the columns, and turn the labels into True/False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1635215172288
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>theme</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>in-need</td>\n",
              "      <td>The ones in need of constant medical care are ...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>immigrant</td>\n",
              "      <td>NBC and Spanish-language Univision both declin...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>in-need</td>\n",
              "      <td>A second T-Home project is being launched in t...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>poor-families</td>\n",
              "      <td>Camfed would like to see this trend reversed ....</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>refugee</td>\n",
              "      <td>Kagunga village was reported to lack necessary...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10633</th>\n",
              "      <td>immigrant</td>\n",
              "      <td>To me , I am always mindful that we are dealin...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10634</th>\n",
              "      <td>vulnerable</td>\n",
              "      <td>Other themes included promoting the inclusion ...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10635</th>\n",
              "      <td>immigrant</td>\n",
              "      <td>It came as the CDU was also humiliated by the ...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10636</th>\n",
              "      <td>hopeless</td>\n",
              "      <td>Those were only days of helplessness , she say...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10637</th>\n",
              "      <td>immigrant</td>\n",
              "      <td>They include a community college student , a c...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10635 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               theme                                               text  label\n",
              "2            in-need  The ones in need of constant medical care are ...  False\n",
              "3          immigrant  NBC and Spanish-language Univision both declin...  False\n",
              "4            in-need  A second T-Home project is being launched in t...  False\n",
              "5      poor-families  Camfed would like to see this trend reversed ....   True\n",
              "6            refugee  Kagunga village was reported to lack necessary...  False\n",
              "...              ...                                                ...    ...\n",
              "10633      immigrant  To me , I am always mindful that we are dealin...   True\n",
              "10634     vulnerable  Other themes included promoting the inclusion ...  False\n",
              "10635      immigrant  It came as the CDU was also humiliated by the ...  False\n",
              "10636       hopeless  Those were only days of helplessness , she say...  False\n",
              "10637      immigrant  They include a community college student , a c...  False\n",
              "\n",
              "[10635 rows x 3 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = df[2:]\n",
        "df = df.rename(columns={\"Column2\":\"theme\", \"Column4\":\"text\", \"Column5\":\"label\"})\n",
        "df[\"label\"] = df[\"label\"] >= 2.0\n",
        "df = df.dropna()\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Set up word embeddings and paragraph embeddings for SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1635215226565
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Beginning pre-trained word embedding download\n",
            "\n",
            "Loading completed\n",
            "Vocab size: 3000000\n"
          ]
        }
      ],
      "source": [
        "# This cell is boilerplate copied from the HW3 word_embedding.ipynb\n",
        "import gensim.downloader as api\n",
        "\n",
        "def download_word2vec_embeddings():\n",
        "    print(\"Beginning pre-trained word embedding download\")\n",
        "    wv = api.load(\"word2vec-google-news-300\")\n",
        "    print(f\"\\nLoading completed\\nVocab size: {len(wv.vocab)}\")\n",
        "    return wv\n",
        "\n",
        "word2vec = download_word2vec_embeddings()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1635216579602
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (3.6.5)\r\n",
            "Requirement already satisfied: click in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from nltk) (8.0.1)\r\n",
            "Requirement already satisfied: joblib in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from nltk) (0.14.1)\r\n",
            "Requirement already satisfied: regex>=2021.8.3 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from nltk) (2021.8.28)\r\n",
            "Requirement already satisfied: tqdm in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from nltk) (4.62.2)\r\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from click->nltk) (4.8.1)\r\n",
            "Requirement already satisfied: zipp>=0.5 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from importlib-metadata; python_version < \"3.8\"->click->nltk) (3.5.0)\r\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from importlib-metadata; python_version < \"3.8\"->click->nltk) (3.10.0.2)\r\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /home/azureuser/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# boilerplate tokenization as done on the HW\n",
        "!pip install nltk\n",
        "import nltk\n",
        "from preprocess import clean_text\n",
        "nltk.download('punkt')\n",
        "df[\"tokenized\"] = df[\"text\"].apply(lambda x: nltk.word_tokenize(clean_text(x)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1635215238532
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "# Generate paragraph embeddings for a given text by averaging (which is what I assume they did)\n",
        "def paragraph_embedding(sentence: list) -> np.ndarray:\n",
        "    words = [word for word in sentence if word in word2vec.vocab]\n",
        "    return np.mean(word2vec[words], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1635215238704
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from sklearn import model_selection\n",
        "train_X, test_X, train_Y, test_Y = model_selection.train_test_split(df[\"tokenized\"],df[\"label\"],test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1635215238829
        }
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "Encoder = LabelEncoder()\n",
        "train_Y = Encoder.fit_transform(train_Y)\n",
        "test_Y = Encoder.fit_transform(test_Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1635215239923
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(8508, 300)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# TODO turn the train_X into a 2d sample x feature vector using paragraph_embedding\n",
        "train_X_para_embed = np.array([paragraph_embedding(text) for text in train_X])\n",
        "test_X_para_embed = np.array([paragraph_embedding(text) for text in test_X])\n",
        "train_X_para_embed.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## SVM-WV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1635215825929
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "#Model based on hyperperameters found here https://aclanthology.org/2020.coling-main.518.pdf\n",
        "SVM = SVC(C=100, kernel=\"poly\", gamma=\"scale\")\n",
        "SVM.fit(train_X_para_embed,train_Y)\n",
        "predictions_SVM = SVM.predict(test_X_para_embed)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1635215826103
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.93      0.94      1962\n",
            "           1       0.36      0.44      0.40       165\n",
            "\n",
            "    accuracy                           0.90      2127\n",
            "   macro avg       0.66      0.69      0.67      2127\n",
            "weighted avg       0.91      0.90      0.90      2127\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(predictions_SVM, test_Y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## SVM-BoW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1635215727438
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<10635x29999 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 370808 stored elements in Compressed Sparse Row format>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "train_X_bow = vectorizer.fit_transform(df['text'])\n",
        "train_X_bow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1635215906764
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "#Model based on hyperperameters found here https://aclanthology.org/2020.coling-main.518.pdf\n",
        "SVM_bow = SVC(C=10, kernel=\"rbf\", gamma=\"scale\")\n",
        "SVM_bow.fit(train_X_para_embed,train_Y)\n",
        "predictions_SVM_bow = SVM_bow.predict(test_X_para_embed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1635215909058
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.93      0.96      2047\n",
            "           1       0.26      0.68      0.38        80\n",
            "\n",
            "    accuracy                           0.92      2127\n",
            "   macro avg       0.63      0.80      0.67      2127\n",
            "weighted avg       0.96      0.92      0.93      2127\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(predictions_SVM_bow, test_Y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Bi-Directional LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'lstm'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-d5fe4349d09e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlstm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClassificationModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClassificationModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'lstm'"
          ]
        }
      ],
      "source": [
        "from lstm import ClassificationModel\n",
        "\n",
        "model = ClassificationModel()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "33101485d82e1dd7cac8a904206c68c0706cfe2ed15a0e0ff261d392afd3bed3"
    },
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
